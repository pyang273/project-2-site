<!doctype html>
<html lang="en">
<head>
  <meta charset="utf-8" />
  <meta name="viewport" content="width=device-width, initial-scale=1" />
  <title>Tech Hero — Dr. Timnit Gebru</title>
  <link rel="stylesheet" href="style.css" />
  <!-- h1: Tech Hero page with image added -->
</head>
<body>
  <a class="skip-link" href="#content">Skip to content</a>

  <!-- masthead with tabs; Tech Hero active -->
  <header class="site-header">
    <div class="wrap">
      <div class="masthead">
        <h1 class="m-0">Tech Hero</h1>
        <nav class="tabs">
          <a href="index.html">Home</a>
          <a href="about.html">About</a>
          <a href="resources.html">Resources</a>
          <a href="hero.html" aria-current="page">Tech Hero</a>
        </nav>
      </div>
    </div>
  </header>

  <main id="content" class="wrap">
    <article class="panel">
      <h2 class="m-0">Dr. Timnit Gebru</h2>
      <p class="lead mt-1">
        Computer scientist and advocate for ethical, accountable AI—pushing the field to confront bias, labor, and power.
      </p>

      <!-- IMAGE of Tech Hero -->
      <figure class="mt-2 mb-2">
        <img src="assets/images/dr-timnit-gebru.jpg" alt="Dr. Timnit Gebru" class="rounded">
        <figcaption class="lead">Dr. Timnit Gebru — Advocate for ethical, accountable AI</figcaption>
      </figure>

      <p>
        Dr. Timnit Gebru is known for foundational work on algorithmic bias and for championing the people most affected by AI systems.
        As a researcher and the founder of the Distributed AI Research Institute (DAIR), she centers impacted communities in the study of data and models.
        Her scholarship on facial analysis disparities and documentation practices helped move “AI ethics” from an afterthought to a core engineering concern.
      </p>

      <p>
        Gebru challenges norms in at least three ways. First, she treats datasets as sociotechnical artifacts—asking who is represented, who is missing, and who bears the risk.
        Second, she connects AI to labor and environment: models depend on large amounts of human annotation and energy; costs and harms are unevenly distributed.
        Third, she shows how organizational incentives shape what gets built. Accountability can’t be outsourced to a single “ethics” role—it must live in requirements, reviews, and deployment standards.
      </p>

      <p>
        For students and new engineers, Gebru’s example is practical: learn the math and code, but also trace the whole pipeline—data collection, labeling, training, evaluation, and real-world impact.
        Document assumptions; measure harms; widen the review circle; and be willing to pause when evidence of harm is strong.
        In other words, equity is an engineering quality attribute.
      </p>

      <h3>Learn More</h3>
      <ul>
        <li><a href="https://www.dair-institute.org/">Distributed AI Research Institute (DAIR)</a></li>
        <li><a href="https://scholar.google.com/scholar?q=Timnit+Gebru">Selected publications</a></li>
        <li><a href="https://www.youtube.com/results?search_query=Timnit+Gebru+talk">Talks & interviews</a></li>
      </ul>
    </article>
  </main>

  <footer>
    <div class="wrap center"><small>© LIS 500 Project 2</small></div>
  </footer>
</body>
</html>

